# -*- coding: utf-8 -*-
"""Copy of Note.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lt754vL2NLDxq6IJ8kmr93odo0mLMKlX

# Proposed Unsupervised Contextual Anomaly Detection Model
---
[link to paper](https://www.skopik.at/ait/2018_ispec.pdf)

1. Parse log file, text preprocessing
2. Feature Engineering with word embedding model (ex. Word2Vec, BERT, Universal Sentence Encoder etc.)
3. Cluster log lines into k groups (K-Means etc.)
4. Determine cluster counts occurring within fixed time windows, t
5. Compute moving averages of cluster counts (or more robust models such as LSTM)
6. Forecast one-timestep ahead
7. Compute confidence interval for forecast and classify anomalies based on this interval

### Install requirnments 
```bash
$ pip install numpy pandas nltk gensim tqdm
$ pip install scipy scikit-learn keras
```


from google.colab import drive
drive.mount('/content/drive')
"""
import pandas as pd
import numpy as np

df = pd.read_csv("log-data.csv")   #csv file with random time added

df

"""**Make the text file for word tokenization**"""

import os 
name_of_text_file = 'input.txt'

if name_of_text_file not in os.listdir(os.getcwd()):
    
    filedata = df['Content'] + " " + df['EventTemplate']+ " "

    s = [x for x in filedata]
    text = ''.join(s)

    text_file = open("input.txt", "w")      
    text_file.write(text)
    text_file.close()

"""## Word2Vec Modeling """

from nltk.tokenize import sent_tokenize, word_tokenize 
import gensim 
from tqdm import tqdm

sample = open('./input.txt', "r") 
s = sample.read() 

f = s.replace("\n", " ")
symbols = ['/', '<', '>', ':', '.', ':', '*']          # to filter out the symbols 
data = [] 

for i in tqdm(sent_tokenize(f)): 
    temp = [] 
    for j in word_tokenize(i):
        if j not in symbols:
            temp.append(j.lower()) 

    data.append(temp) 

# Create CBOW model 
model1 = gensim.models.Word2Vec(data, min_count = 1, size = 32, window = 5)

model1.most_similar('NameSystem.allocateBlock'.lower())

print(model1.similarity('NameSystem.allocateBlock'.lower(), 'succeeded'))

"""#### Make sentence vec"""

sen = df['Content'] + ' ' + df['EventTemplate']

sen2vec = []
for x in sen:
    for i in sent_tokenize(x): 
        temp = [] 
        for j in word_tokenize(i):
            if j not in symbols:
                try:
                    temp.append(model1[j.lower()])
                except:
                    print(j)
    l = np.array(temp)
    l = np.average(l,axis=0)
    sen2vec.append(l)

sen2vec = np.array(sen2vec)

sen2vec.shape

"""#### window generator"""

from datetime import datetime, timedelta
class DataGen:
    def __init__(self, time, window):
        self.time = time
        self.window = timedelta(minutes=window)
        self.index = 0
        self.start = datetime.strptime(self.time[0], "%H:%M:%S") 
        self.it = 1

    def __iter__(self):
        return self

    def __next__(self): 
        self.indextime = datetime.strptime(self.time[self.index], "%H:%M:%S")
        for x in range(self.index, len(self.time)):
            temp =  datetime.strptime(self.time[x], "%H:%M:%S") 
            if temp - self.start >= self.window*self.it:
                self.index = x
                self.it+=1
                return self.index
        raise StopIteration
        
        
def extract_max_min(dic):
    max_value = -1
    min_value = 100000000
    for x in dic:
        if dic[x] > max_value:
            max_value = dic[x]
        if dic[x] < min_value:
            min_value = dic[x]
    return max_value, min_value

for x in DataGen(df["Time"], window=2):
    print(x)
    print(df["Time"][x])
    break

sen2vec[0:147].shape

"""## Step 3 - Auto K mean algo"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score

import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
from tqdm import tqdm
# %matplotlib inline

plt.style.use('ggplot')

training_file_name = 'k_values.npy'

if name_of_text_file not in os.listdir(os.getcwd()):
    range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

    k_values = []
    cluster_values = []

    start = 0
    for end in tqdm(DataGen(df["Time"], window=2)):

        X = sen2vec[start:end]
        start, end = end, _

        k_values_score = []
        clusters = []
        for n_clusters in range_n_clusters:

            clusterer = KMeans(n_clusters=n_clusters, random_state=10)
            cluster_labels = clusterer.fit_predict(X)
            unique, counts = np.unique(cluster_labels, return_counts=True)
            stats = dict(zip(unique, counts))
            max_value, min_value = extract_max_min(stats)
            clusters.append([max_value, min_value])
            silhouette_avg = silhouette_score(X, cluster_labels)
            k_values_score.append(silhouette_avg)    
        
    #     print(k_values_score)
        i = np.argmax(k_values_score)
        k_value = range_n_clusters[i]
        max_value, min_value = clusters[i]
        cluster_values.append([max_value, min_value])
        k_values.append(k_value)

"""https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py"""

# np.save('k_values.npy', k_values)          # save the result of training in k_values.npy file

# np.save('cluster_values.npy', cluster_values)

k_values = np.load('k_values.npy')        # load the result of training from k_values.npy file
cluster_values = np.load('cluster_values.npy')

from matplotlib.pyplot import figure
figure(num=None, figsize=(16, 8), dpi=80, facecolor='w', edgecolor='k')
plt.plot(k_values, '-')
plt.title("time window 2 min")
plt.xlabel("time")
plt.ylabel("k-number")

fig = figure(num=None, figsize=(16, 8), dpi=80)
plt.plot(cluster_values[:,0], '-', label='max')
plt.plot(cluster_values[:,1], '-', label='min')

plt.title("time window 2 min")
plt.xlabel("time")
plt.ylabel("cluster size")
plt.savefig("min_max_cluster_size")
plt.legend()

"""## Model """

from pandas import DataFrame
from pandas import Series
from pandas import concat
from pandas import read_csv
from pandas import datetime
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from math import sqrt

def timeseries_to_supervised(data, lag=1):
    df = DataFrame(data)
    columns = [df.shift(i) for i in range(1, lag+1)]
    columns.append(df)
    df = concat(columns, axis=1)
    df.fillna(0, inplace=True)

    return df
# create a differenced series


def difference(dataset, interval=1):
    diff = list()
    for i in range(interval, len(dataset)):
        value = dataset[i] - dataset[i - interval]
        diff.append(value)
    return Series(diff)
# invert differenced value


def inverse_difference(history, yhat, interval=1):
    return yhat + history[-interval]
# scale train and test data to [-1, 1]


def scale(train, test):
    # fit scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train)
    # transform train
    train = train.reshape(train.shape[0], train.shape[1])
    train_scaled = scaler.transform(train)
    # transform test
    test = test.reshape(test.shape[0], test.shape[1])
    test_scaled = scaler.transform(test)
    return scaler, train_scaled, test_scaled
# inverse scaling for a forecasted value


def invert_scale(scaler, X, value):
    new_row = [x for x in X] + [value]
    array = np.array(new_row)
    array = array.reshape(1, len(array))
    inverted = scaler.inverse_transform(array)
    return inverted[0, -1]
# fit an LSTM network to training data


def fit_lstm(train, batch_size, nb_epoch, neurons):
    X, y = train[:, 0:-1], train[:, -1]
    X = X.reshape(X.shape[0], 1, X.shape[1])
    model = Sequential()
    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    for i in range(nb_epoch):
        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)
        model.reset_states()
    return model
# make a one-step forecast


def forecast_lstm(model, batch_size, X):
    X = X.reshape(1, 1, len(X))
    yhat = model.predict(X, batch_size=batch_size)
    return yhat[0,0]

"""#### LSTM model training """

data = (cluster_values[:,0] + cluster_values[:,1])/2
supervised = timeseries_to_supervised(data, 1)
supervised_values = supervised.values

test_size = 100

train_lstm, test_lstm = supervised_values[0:-test_size], supervised_values[-test_size:]
# transform the scale of the data
scaler, train_scaled_lstm, test_scaled_lstm = scale(train_lstm, test_lstm)

# fit the model                 batch,Epoch,Neurons
lstm_model = fit_lstm(train_scaled_lstm, 1, 64 , 64)
# forecast the entire training dataset to build up state for forecasting
train_reshaped = train_scaled_lstm[:, 0].reshape(len(train_scaled_lstm), 1, 1)
#lstm_model.predict(train_reshaped, batch_size=1)

from matplotlib import pyplot
import matplotlib.pyplot as plt
from tqdm import tqdm
from matplotlib.patches import Ellipse


predictions = list()
predictions_std = list()

for i in tqdm(range(0,len(test_scaled_lstm))):
#make one-step forecast
    X, y = test_scaled_lstm[i, 0:-1], test_scaled_lstm[i, -1]
    
    stats = []
    for x in range(10):
        yhat = forecast_lstm(lstm_model, 1, X)
        # invert scaling
        yhat = invert_scale(scaler, X, yhat)
        stats.append(yhat)
    stats = np.array(stats)
    yhat = stats.mean()
    yhat_std = stats.std()
    
    # store forecast
    predictions.append(yhat)
    predictions_std.append(yhat_std)
    expected = k_values[len(train_lstm) + i ]

threshold = 3
anomly_location = []
for x in range(len(predictions_std)):
    if predictions_std[x] > threshold:
        print(x)
        anomly_location.append(x)

"""## graphs"""

# line plot of observed vs predicted
figsize=(12, 12)
fig, axs = plt.subplots(2,figsize=figsize)


axs[0].plot(data[-test_size:],color='blue',label='Actuals')
axs[0].plot(predictions,'r-',label='Predicted')

anomly_index=0
for loc in anomly_location:
    anomly_index+=1
    circle = Ellipse((loc, predictions[loc]), width=5, height=7.5 , color='pink',alpha=0.7, fill=True, label=f'Anomly location {anomly_index}')
    axs[0].add_patch(circle)

axs[1].plot(predictions_std,'--',label='Predicted_std')
axs[1].axhline(y=3, color='r', linestyle='--',label='threshold')


axs[0].legend(loc='upper left')
axs[1].legend(loc='upper left')

# axs[0].set_ylim([1,12])
axs[0].set_xlabel('time * 2 min')
axs[1].set_xlabel('time * 2 min')
axs[1].set_ylabel('standard deviation value')


axs[1].grid(True)
plt.savefig('Anomly_loc.png')
plt.show()

predicted_df=pd.DataFrame()
predicted_df['actuals']=data[-test_size:]
predicted_df['predicted']=predictions
predicted_df.reset_index(inplace=True)

df = predicted_df['predicted']

fig, ax1 = plt.subplots(1, 1,figsize=(15, 8))
ax1.plot(cluster_values[-100:,0],'--', label='max')
ax1.plot(cluster_values[-100:,1],'--', label='min')

ax1.plot(list(df.index), df.iloc[:],'r.',label='Predicted')
ax1.plot(list(df.index), predicted_df['actuals'],label='Real values')
ax1.plot(list(df.index), predicted_df['actuals'],label='Moving Average')
ax1.plot(list(df.index), df.rolling(window=3).mean(),'r',label='Moving Average')

mu = df.rolling(window=3).mean()
sigma = df.rolling(window=3).std()
one_sigma_pos = mu+sigma
one_sigma_neg = mu-sigma
two_sigma_pos = mu+2*sigma
two_sigma_neg = mu-2*sigma
three_sigma_pos = mu+3*sigma
three_sigma_neg = mu-3*sigma

ax1.fill_between(df.index, one_sigma_pos, one_sigma_neg ,color='pink',alpha=0.5,label='1-Sigma')
ax1.fill_between(df.index, two_sigma_pos, two_sigma_neg ,color='pink',alpha=0.4,label='2-Sigma')
ax1.fill_between(df.index, three_sigma_pos, three_sigma_neg ,color='pink',alpha=0.3,label='3-Sigma')


ax1.set_xlabel('time * 2 min')
ax1.set_ylabel('Cluster size')
ax1.set_title('Data prediction for last 200 min')

ax1.legend();
plt.savefig('mu-sigma.png')
plt.show()

"""https://datascience.stackexchange.com/questions/42715/how-to-calculate-prediction-error-in-a-lstm-keras

https://medium.com/hal24k-techblog/how-to-generate-neural-network-confidence-intervals-with-keras-e4c0b78ebbdf
"""